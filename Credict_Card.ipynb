{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jmI_NZkBpGg"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhCs0LCuBxeW",
        "outputId": "6162cbf7-f9f5-4008-b892-060438859a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#reading the data\n",
        "data = pd.read_csv(\"creditcard.csv\")\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU9I9KGQiPSg"
      },
      "outputs": [],
      "source": [
        "#separating the data into independent and depenent variable\n",
        "x=data.iloc[:,:-1]\n",
        "y=data.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removing oversampling\n",
        "over_sampler = SMOTE(sampling_strategy=\"minority\")\n",
        "X_oversampled, Y_oversampled = over_sampler.fit_resample(x, y)\n"
      ],
      "metadata": {
        "id": "Nl9dLu47gZX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6qjsj7ZB8mj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp_YvMQ2gPSJ"
      },
      "outputs": [],
      "source": [
        "#filling the missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(x)\n",
        "x = imputer.transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh6E5CdZe9VM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RMx707OgA3o",
        "outputId": "ddefcf11-c2be-41ee-8f91-0f36f10e4800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.00e+00 -1.36e+00 -7.28e-02 ...  1.34e-01 -2.11e-02  1.50e+02]\n",
            " [ 0.00e+00  1.19e+00  2.66e-01 ... -8.98e-03  1.47e-02  2.69e+00]\n",
            " [ 1.00e+00 -1.36e+00 -1.34e+00 ... -5.54e-02 -5.98e-02  3.79e+02]\n",
            " ...\n",
            " [ 1.73e+05  1.92e+00 -3.01e-01 ...  4.45e-03 -2.66e-02  6.79e+01]\n",
            " [ 1.73e+05 -2.40e-01  5.30e-01 ...  1.09e-01  1.05e-01  1.00e+01]\n",
            " [ 1.73e+05 -5.33e-01 -1.90e-01 ... -2.42e-03  1.36e-02  2.17e+02]]\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyWau7GQecwc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7VZ74QNgeO-",
        "outputId": "a613507b-2df2-42de-8288-6ab648eb3673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.00e+00  0.00e+00 -1.36e+00 ...  1.34e-01 -2.11e-02  1.50e+02]\n",
            " [ 1.00e+00  0.00e+00  1.19e+00 ... -8.98e-03  1.47e-02  2.69e+00]\n",
            " [ 1.00e+00  1.00e+00 -1.36e+00 ... -5.54e-02 -5.98e-02  3.79e+02]\n",
            " ...\n",
            " [ 1.00e+00  1.73e+05  1.92e+00 ...  4.45e-03 -2.66e-02  6.79e+01]\n",
            " [ 1.00e+00  1.73e+05 -2.40e-01 ...  1.09e-01  1.05e-01  1.00e+01]\n",
            " [ 1.00e+00  1.73e+05 -5.33e-01 ... -2.42e-03  1.36e-02  2.17e+02]]\n"
          ]
        }
      ],
      "source": [
        "#Feature extraction\n",
        "import statsmodels.api as sm\n",
        "X = np.append(arr = np.ones((284807, 1)).astype(int), values = x, axis = 1)\n",
        "X_opt = X[:, [0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15,16,1,7,18,19,20,21,22,23,24,25,26,27,28,29,30]]\n",
        "X_opt = X_opt.astype(np.float64)\n",
        "print(X_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0MpyS7fee_Mp",
        "outputId": "7c254344-612c-4b13-99c3-d71fac260d6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                  Class   R-squared:                       0.483\n",
              "Model:                            OLS   Adj. R-squared:                  0.483\n",
              "Method:                 Least Squares   F-statistic:                     9178.\n",
              "Date:                Wed, 16 Aug 2023   Prob (F-statistic):               0.00\n",
              "Time:                        08:42:23   Log-Likelihood:             5.9594e+05\n",
              "No. Observations:              284807   AIC:                        -1.192e+06\n",
              "Df Residuals:                  284777   BIC:                        -1.192e+06\n",
              "Df Model:                          29                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.0017      0.000      9.803      0.000       0.001       0.002\n",
              "x1         -4.103e-09   8.08e-10     -5.080      0.000   -5.69e-09   -2.52e-09\n",
              "x2            -0.0019   3.67e-05    -51.032      0.000      -0.002      -0.002\n",
              "x3             0.0030   7.12e-05     41.979      0.000       0.003       0.003\n",
              "x4            -0.0051   5.06e-05   -100.704      0.000      -0.005      -0.005\n",
              "x5             0.0037   4.22e-05     88.580      0.000       0.004       0.004\n",
              "x6            -0.0022   6.85e-05    -32.128      0.000      -0.002      -0.002\n",
              "x7            -0.0009   2.63e-05    -32.867      0.000      -0.001      -0.001\n",
              "x8            -0.0070   7.74e-05    -89.867      0.000      -0.007      -0.007\n",
              "x9             0.0009   4.98e-05     17.380      0.000       0.001       0.001\n",
              "x10           -0.0036   5.15e-05    -70.057      0.000      -0.004      -0.004\n",
              "x11           -0.0081   5.45e-05   -147.783      0.000      -0.008      -0.008\n",
              "x12            0.0062   5.79e-05    107.217      0.000       0.006       0.006\n",
              "x13           -0.0108   5.68e-05   -189.367      0.000      -0.011      -0.011\n",
              "x14           -0.0002   5.65e-05     -4.039      0.000      -0.000      -0.000\n",
              "x15           -0.0132   5.93e-05   -223.039      0.000      -0.013      -0.013\n",
              "x16           -0.0003    6.3e-05     -4.167      0.000      -0.000      -0.000\n",
              "x17        -4.103e-09   8.08e-10     -5.080      0.000   -5.69e-09   -2.52e-09\n",
              "x18           -0.0009   2.63e-05    -32.867      0.000      -0.001      -0.001\n",
              "x19           -0.0160   6.62e-05   -241.838      0.000      -0.016      -0.016\n",
              "x20           -0.0056   6.78e-05    -82.236      0.000      -0.006      -0.005\n",
              "x21            0.0019   7.01e-05     27.653      0.000       0.002       0.002\n",
              "x22            0.0001      0.000      0.910      0.363      -0.000       0.000\n",
              "x23            0.0020   8.13e-05     24.538      0.000       0.002       0.002\n",
              "x24            0.0003   8.05e-05      3.940      0.000       0.000       0.000\n",
              "x25            0.0002   9.64e-05      2.534      0.011    5.53e-05       0.000\n",
              "x26           -0.0005   9.24e-05     -5.670      0.000      -0.001      -0.000\n",
              "x27            0.0003      0.000      2.525      0.012    6.45e-05       0.001\n",
              "x28            0.0004      0.000      3.138      0.002       0.000       0.001\n",
              "x29            0.0016      0.000     11.837      0.000       0.001       0.002\n",
              "x30            0.0011      0.000      6.611      0.000       0.001       0.001\n",
              "x31         8.666e-06   7.79e-07     11.131      0.000    7.14e-06    1.02e-05\n",
              "==============================================================================\n",
              "Omnibus:                   593594.746   Durbin-Watson:                   1.973\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       5942385671.781\n",
              "Skew:                          17.542   Prob(JB):                         0.00\n",
              "Kurtosis:                     709.767   Cond. No.                     1.12e+16\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The smallest eigenvalue is 5.11e-17. This might indicate that there are\n",
              "strong multicollinearity problems or that the design matrix is singular.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>Class</td>      <th>  R-squared:         </th>  <td>   0.483</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.483</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   9178.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 16 Aug 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>08:42:23</td>     <th>  Log-Likelihood:    </th> <td>5.9594e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>284807</td>      <th>  AIC:               </th> <td>-1.192e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>284777</td>      <th>  BIC:               </th> <td>-1.192e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    29</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.0017</td> <td>    0.000</td> <td>    9.803</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>-4.103e-09</td> <td> 8.08e-10</td> <td>   -5.080</td> <td> 0.000</td> <td>-5.69e-09</td> <td>-2.52e-09</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>   -0.0019</td> <td> 3.67e-05</td> <td>  -51.032</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>    0.0030</td> <td> 7.12e-05</td> <td>   41.979</td> <td> 0.000</td> <td>    0.003</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.0051</td> <td> 5.06e-05</td> <td> -100.704</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.0037</td> <td> 4.22e-05</td> <td>   88.580</td> <td> 0.000</td> <td>    0.004</td> <td>    0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>   -0.0022</td> <td> 6.85e-05</td> <td>  -32.128</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   -0.0009</td> <td> 2.63e-05</td> <td>  -32.867</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>   -0.0070</td> <td> 7.74e-05</td> <td>  -89.867</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>    0.0009</td> <td> 4.98e-05</td> <td>   17.380</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>   -0.0036</td> <td> 5.15e-05</td> <td>  -70.057</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>   -0.0081</td> <td> 5.45e-05</td> <td> -147.783</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>    0.0062</td> <td> 5.79e-05</td> <td>  107.217</td> <td> 0.000</td> <td>    0.006</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x13</th>   <td>   -0.0108</td> <td> 5.68e-05</td> <td> -189.367</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x14</th>   <td>   -0.0002</td> <td> 5.65e-05</td> <td>   -4.039</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x15</th>   <td>   -0.0132</td> <td> 5.93e-05</td> <td> -223.039</td> <td> 0.000</td> <td>   -0.013</td> <td>   -0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x16</th>   <td>   -0.0003</td> <td>  6.3e-05</td> <td>   -4.167</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x17</th>   <td>-4.103e-09</td> <td> 8.08e-10</td> <td>   -5.080</td> <td> 0.000</td> <td>-5.69e-09</td> <td>-2.52e-09</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x18</th>   <td>   -0.0009</td> <td> 2.63e-05</td> <td>  -32.867</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x19</th>   <td>   -0.0160</td> <td> 6.62e-05</td> <td> -241.838</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x20</th>   <td>   -0.0056</td> <td> 6.78e-05</td> <td>  -82.236</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x21</th>   <td>    0.0019</td> <td> 7.01e-05</td> <td>   27.653</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x22</th>   <td>    0.0001</td> <td>    0.000</td> <td>    0.910</td> <td> 0.363</td> <td>   -0.000</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x23</th>   <td>    0.0020</td> <td> 8.13e-05</td> <td>   24.538</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x24</th>   <td>    0.0003</td> <td> 8.05e-05</td> <td>    3.940</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x25</th>   <td>    0.0002</td> <td> 9.64e-05</td> <td>    2.534</td> <td> 0.011</td> <td> 5.53e-05</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x26</th>   <td>   -0.0005</td> <td> 9.24e-05</td> <td>   -5.670</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x27</th>   <td>    0.0003</td> <td>    0.000</td> <td>    2.525</td> <td> 0.012</td> <td> 6.45e-05</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x28</th>   <td>    0.0004</td> <td>    0.000</td> <td>    3.138</td> <td> 0.002</td> <td>    0.000</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x29</th>   <td>    0.0016</td> <td>    0.000</td> <td>   11.837</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x30</th>   <td>    0.0011</td> <td>    0.000</td> <td>    6.611</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x31</th>   <td> 8.666e-06</td> <td> 7.79e-07</td> <td>   11.131</td> <td> 0.000</td> <td> 7.14e-06</td> <td> 1.02e-05</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>593594.746</td> <th>  Durbin-Watson:     </th>    <td>   1.973</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>5942385671.781</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>            <td>17.542</td>   <th>  Prob(JB):          </th>    <td>    0.00</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>        <td>709.767</td>  <th>  Cond. No.          </th>    <td>1.12e+16</td>   \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.11e-17. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &      Class       & \\textbf{  R-squared:         } &       0.483     \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &       0.483     \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &       9178.     \\\\\n\\textbf{Date:}             & Wed, 16 Aug 2023 & \\textbf{  Prob (F-statistic):} &       0.00      \\\\\n\\textbf{Time:}             &     08:42:23     & \\textbf{  Log-Likelihood:    } &   5.9594e+05    \\\\\n\\textbf{No. Observations:} &      284807      & \\textbf{  AIC:               } &   -1.192e+06    \\\\\n\\textbf{Df Residuals:}     &      284777      & \\textbf{  BIC:               } &   -1.192e+06    \\\\\n\\textbf{Df Model:}         &          29      & \\textbf{                     } &                 \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &                 \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &       0.0017  &        0.000     &     9.803  &         0.000        &        0.001    &        0.002     \\\\\n\\textbf{x1}    &   -4.103e-09  &     8.08e-10     &    -5.080  &         0.000        &    -5.69e-09    &    -2.52e-09     \\\\\n\\textbf{x2}    &      -0.0019  &     3.67e-05     &   -51.032  &         0.000        &       -0.002    &       -0.002     \\\\\n\\textbf{x3}    &       0.0030  &     7.12e-05     &    41.979  &         0.000        &        0.003    &        0.003     \\\\\n\\textbf{x4}    &      -0.0051  &     5.06e-05     &  -100.704  &         0.000        &       -0.005    &       -0.005     \\\\\n\\textbf{x5}    &       0.0037  &     4.22e-05     &    88.580  &         0.000        &        0.004    &        0.004     \\\\\n\\textbf{x6}    &      -0.0022  &     6.85e-05     &   -32.128  &         0.000        &       -0.002    &       -0.002     \\\\\n\\textbf{x7}    &      -0.0009  &     2.63e-05     &   -32.867  &         0.000        &       -0.001    &       -0.001     \\\\\n\\textbf{x8}    &      -0.0070  &     7.74e-05     &   -89.867  &         0.000        &       -0.007    &       -0.007     \\\\\n\\textbf{x9}    &       0.0009  &     4.98e-05     &    17.380  &         0.000        &        0.001    &        0.001     \\\\\n\\textbf{x10}   &      -0.0036  &     5.15e-05     &   -70.057  &         0.000        &       -0.004    &       -0.004     \\\\\n\\textbf{x11}   &      -0.0081  &     5.45e-05     &  -147.783  &         0.000        &       -0.008    &       -0.008     \\\\\n\\textbf{x12}   &       0.0062  &     5.79e-05     &   107.217  &         0.000        &        0.006    &        0.006     \\\\\n\\textbf{x13}   &      -0.0108  &     5.68e-05     &  -189.367  &         0.000        &       -0.011    &       -0.011     \\\\\n\\textbf{x14}   &      -0.0002  &     5.65e-05     &    -4.039  &         0.000        &       -0.000    &       -0.000     \\\\\n\\textbf{x15}   &      -0.0132  &     5.93e-05     &  -223.039  &         0.000        &       -0.013    &       -0.013     \\\\\n\\textbf{x16}   &      -0.0003  &      6.3e-05     &    -4.167  &         0.000        &       -0.000    &       -0.000     \\\\\n\\textbf{x17}   &   -4.103e-09  &     8.08e-10     &    -5.080  &         0.000        &    -5.69e-09    &    -2.52e-09     \\\\\n\\textbf{x18}   &      -0.0009  &     2.63e-05     &   -32.867  &         0.000        &       -0.001    &       -0.001     \\\\\n\\textbf{x19}   &      -0.0160  &     6.62e-05     &  -241.838  &         0.000        &       -0.016    &       -0.016     \\\\\n\\textbf{x20}   &      -0.0056  &     6.78e-05     &   -82.236  &         0.000        &       -0.006    &       -0.005     \\\\\n\\textbf{x21}   &       0.0019  &     7.01e-05     &    27.653  &         0.000        &        0.002    &        0.002     \\\\\n\\textbf{x22}   &       0.0001  &        0.000     &     0.910  &         0.363        &       -0.000    &        0.000     \\\\\n\\textbf{x23}   &       0.0020  &     8.13e-05     &    24.538  &         0.000        &        0.002    &        0.002     \\\\\n\\textbf{x24}   &       0.0003  &     8.05e-05     &     3.940  &         0.000        &        0.000    &        0.000     \\\\\n\\textbf{x25}   &       0.0002  &     9.64e-05     &     2.534  &         0.011        &     5.53e-05    &        0.000     \\\\\n\\textbf{x26}   &      -0.0005  &     9.24e-05     &    -5.670  &         0.000        &       -0.001    &       -0.000     \\\\\n\\textbf{x27}   &       0.0003  &        0.000     &     2.525  &         0.012        &     6.45e-05    &        0.001     \\\\\n\\textbf{x28}   &       0.0004  &        0.000     &     3.138  &         0.002        &        0.000    &        0.001     \\\\\n\\textbf{x29}   &       0.0016  &        0.000     &    11.837  &         0.000        &        0.001    &        0.002     \\\\\n\\textbf{x30}   &       0.0011  &        0.000     &     6.611  &         0.000        &        0.001    &        0.001     \\\\\n\\textbf{x31}   &    8.666e-06  &     7.79e-07     &    11.131  &         0.000        &     7.14e-06    &     1.02e-05     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 593594.746 & \\textbf{  Durbin-Watson:     } &       1.973     \\\\\n\\textbf{Prob(Omnibus):} &    0.000   & \\textbf{  Jarque-Bera (JB):  } & 5942385671.781  \\\\\n\\textbf{Skew:}          &   17.542   & \\textbf{  Prob(JB):          } &        0.00     \\\\\n\\textbf{Kurtosis:}      &  709.767   & \\textbf{  Cond. No.          } &    1.12e+16     \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The smallest eigenvalue is 5.11e-17. This might indicate that there are \\newline\n strong multicollinearity problems or that the design matrix is singular."
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
        "regressor_OLS.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g1iunSP_hsal",
        "outputId": "0b50562c-b8f6-40d6-ed21-daa0eb0c4645"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                  Class   R-squared:                       0.482\n",
              "Model:                            OLS   Adj. R-squared:                  0.482\n",
              "Method:                 Least Squares   F-statistic:                     9813.\n",
              "Date:                Wed, 16 Aug 2023   Prob (F-statistic):               0.00\n",
              "Time:                        08:42:25   Log-Likelihood:             5.9562e+05\n",
              "No. Observations:              284807   AIC:                        -1.191e+06\n",
              "Df Residuals:                  284779   BIC:                        -1.191e+06\n",
              "Df Model:                          27                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.0009      0.000      5.241      0.000       0.001       0.001\n",
              "x1         -2.798e-09   8.07e-10     -3.468      0.001   -4.38e-09   -1.22e-09\n",
              "x2            -0.0017    3.6e-05    -47.015      0.000      -0.002      -0.002\n",
              "x3             0.0035   6.79e-05     51.791      0.000       0.003       0.004\n",
              "x4            -0.0048   4.95e-05    -97.614      0.000      -0.005      -0.005\n",
              "x5             0.0036    4.2e-05     86.463      0.000       0.004       0.004\n",
              "x6            -0.0018   6.61e-05    -26.615      0.000      -0.002      -0.002\n",
              "x7            -0.0010   2.58e-05    -38.558      0.000      -0.001      -0.001\n",
              "x8            -0.0075   7.43e-05   -100.805      0.000      -0.008      -0.007\n",
              "x9             0.0010   4.95e-05     20.414      0.000       0.001       0.001\n",
              "x10           -0.0035   5.15e-05    -68.782      0.000      -0.004      -0.003\n",
              "x11           -0.0079   5.42e-05   -145.824      0.000      -0.008      -0.008\n",
              "x12            0.0062   5.79e-05    107.637      0.000       0.006       0.006\n",
              "x13           -0.0108   5.69e-05   -189.155      0.000      -0.011      -0.011\n",
              "x14           -0.0002   5.65e-05     -4.043      0.000      -0.000      -0.000\n",
              "x15           -0.0133   5.93e-05   -223.663      0.000      -0.013      -0.013\n",
              "x16           -0.0002   6.31e-05     -3.685      0.000      -0.000      -0.000\n",
              "x17        -2.798e-09   8.07e-10     -3.468      0.001   -4.38e-09   -1.22e-09\n",
              "x18           -0.0010   2.58e-05    -38.558      0.000      -0.001      -0.001\n",
              "x19           -0.0160   6.63e-05   -241.622      0.000      -0.016      -0.016\n",
              "x20           -0.0057   6.78e-05    -83.469      0.000      -0.006      -0.006\n",
              "x21            0.0020      7e-05     29.227      0.000       0.002       0.002\n",
              "x22           -0.0006      0.000     -5.612      0.000      -0.001      -0.000\n",
              "x23            0.0004   8.04e-05      5.454      0.000       0.000       0.001\n",
              "x24            0.0005   9.58e-05      5.523      0.000       0.000       0.001\n",
              "x25            0.0005      0.000      4.332      0.000       0.000       0.001\n",
              "x26            0.0004      0.000      3.319      0.001       0.000       0.001\n",
              "x27            0.0015      0.000     11.004      0.000       0.001       0.002\n",
              "x28            0.0011      0.000      6.325      0.000       0.001       0.001\n",
              "x29          1.52e-05   7.31e-07     20.794      0.000    1.38e-05    1.66e-05\n",
              "==============================================================================\n",
              "Omnibus:                   593907.717   Durbin-Watson:                   1.972\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       5890682278.015\n",
              "Skew:                          17.570   Prob(JB):                         0.00\n",
              "Kurtosis:                     706.675   Cond. No.                     1.12e+16\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The smallest eigenvalue is 5.11e-17. This might indicate that there are\n",
              "strong multicollinearity problems or that the design matrix is singular.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>Class</td>      <th>  R-squared:         </th>  <td>   0.482</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.482</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   9813.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 16 Aug 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>08:42:25</td>     <th>  Log-Likelihood:    </th> <td>5.9562e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>284807</td>      <th>  AIC:               </th> <td>-1.191e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>284779</td>      <th>  BIC:               </th> <td>-1.191e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    27</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.0009</td> <td>    0.000</td> <td>    5.241</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>-2.798e-09</td> <td> 8.07e-10</td> <td>   -3.468</td> <td> 0.001</td> <td>-4.38e-09</td> <td>-1.22e-09</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>   -0.0017</td> <td>  3.6e-05</td> <td>  -47.015</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>    0.0035</td> <td> 6.79e-05</td> <td>   51.791</td> <td> 0.000</td> <td>    0.003</td> <td>    0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.0048</td> <td> 4.95e-05</td> <td>  -97.614</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.0036</td> <td>  4.2e-05</td> <td>   86.463</td> <td> 0.000</td> <td>    0.004</td> <td>    0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>   -0.0018</td> <td> 6.61e-05</td> <td>  -26.615</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   -0.0010</td> <td> 2.58e-05</td> <td>  -38.558</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>   -0.0075</td> <td> 7.43e-05</td> <td> -100.805</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>    0.0010</td> <td> 4.95e-05</td> <td>   20.414</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>   -0.0035</td> <td> 5.15e-05</td> <td>  -68.782</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>   -0.0079</td> <td> 5.42e-05</td> <td> -145.824</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>    0.0062</td> <td> 5.79e-05</td> <td>  107.637</td> <td> 0.000</td> <td>    0.006</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x13</th>   <td>   -0.0108</td> <td> 5.69e-05</td> <td> -189.155</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x14</th>   <td>   -0.0002</td> <td> 5.65e-05</td> <td>   -4.043</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x15</th>   <td>   -0.0133</td> <td> 5.93e-05</td> <td> -223.663</td> <td> 0.000</td> <td>   -0.013</td> <td>   -0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x16</th>   <td>   -0.0002</td> <td> 6.31e-05</td> <td>   -3.685</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x17</th>   <td>-2.798e-09</td> <td> 8.07e-10</td> <td>   -3.468</td> <td> 0.001</td> <td>-4.38e-09</td> <td>-1.22e-09</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x18</th>   <td>   -0.0010</td> <td> 2.58e-05</td> <td>  -38.558</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x19</th>   <td>   -0.0160</td> <td> 6.63e-05</td> <td> -241.622</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x20</th>   <td>   -0.0057</td> <td> 6.78e-05</td> <td>  -83.469</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x21</th>   <td>    0.0020</td> <td>    7e-05</td> <td>   29.227</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x22</th>   <td>   -0.0006</td> <td>    0.000</td> <td>   -5.612</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x23</th>   <td>    0.0004</td> <td> 8.04e-05</td> <td>    5.454</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x24</th>   <td>    0.0005</td> <td> 9.58e-05</td> <td>    5.523</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x25</th>   <td>    0.0005</td> <td>    0.000</td> <td>    4.332</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x26</th>   <td>    0.0004</td> <td>    0.000</td> <td>    3.319</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x27</th>   <td>    0.0015</td> <td>    0.000</td> <td>   11.004</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x28</th>   <td>    0.0011</td> <td>    0.000</td> <td>    6.325</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x29</th>   <td>  1.52e-05</td> <td> 7.31e-07</td> <td>   20.794</td> <td> 0.000</td> <td> 1.38e-05</td> <td> 1.66e-05</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>593907.717</td> <th>  Durbin-Watson:     </th>    <td>   1.972</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>5890682278.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>            <td>17.570</td>   <th>  Prob(JB):          </th>    <td>    0.00</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>        <td>706.675</td>  <th>  Cond. No.          </th>    <td>1.12e+16</td>   \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.11e-17. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &      Class       & \\textbf{  R-squared:         } &       0.482     \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &       0.482     \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &       9813.     \\\\\n\\textbf{Date:}             & Wed, 16 Aug 2023 & \\textbf{  Prob (F-statistic):} &       0.00      \\\\\n\\textbf{Time:}             &     08:42:25     & \\textbf{  Log-Likelihood:    } &   5.9562e+05    \\\\\n\\textbf{No. Observations:} &      284807      & \\textbf{  AIC:               } &   -1.191e+06    \\\\\n\\textbf{Df Residuals:}     &      284779      & \\textbf{  BIC:               } &   -1.191e+06    \\\\\n\\textbf{Df Model:}         &          27      & \\textbf{                     } &                 \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &                 \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &       0.0009  &        0.000     &     5.241  &         0.000        &        0.001    &        0.001     \\\\\n\\textbf{x1}    &   -2.798e-09  &     8.07e-10     &    -3.468  &         0.001        &    -4.38e-09    &    -1.22e-09     \\\\\n\\textbf{x2}    &      -0.0017  &      3.6e-05     &   -47.015  &         0.000        &       -0.002    &       -0.002     \\\\\n\\textbf{x3}    &       0.0035  &     6.79e-05     &    51.791  &         0.000        &        0.003    &        0.004     \\\\\n\\textbf{x4}    &      -0.0048  &     4.95e-05     &   -97.614  &         0.000        &       -0.005    &       -0.005     \\\\\n\\textbf{x5}    &       0.0036  &      4.2e-05     &    86.463  &         0.000        &        0.004    &        0.004     \\\\\n\\textbf{x6}    &      -0.0018  &     6.61e-05     &   -26.615  &         0.000        &       -0.002    &       -0.002     \\\\\n\\textbf{x7}    &      -0.0010  &     2.58e-05     &   -38.558  &         0.000        &       -0.001    &       -0.001     \\\\\n\\textbf{x8}    &      -0.0075  &     7.43e-05     &  -100.805  &         0.000        &       -0.008    &       -0.007     \\\\\n\\textbf{x9}    &       0.0010  &     4.95e-05     &    20.414  &         0.000        &        0.001    &        0.001     \\\\\n\\textbf{x10}   &      -0.0035  &     5.15e-05     &   -68.782  &         0.000        &       -0.004    &       -0.003     \\\\\n\\textbf{x11}   &      -0.0079  &     5.42e-05     &  -145.824  &         0.000        &       -0.008    &       -0.008     \\\\\n\\textbf{x12}   &       0.0062  &     5.79e-05     &   107.637  &         0.000        &        0.006    &        0.006     \\\\\n\\textbf{x13}   &      -0.0108  &     5.69e-05     &  -189.155  &         0.000        &       -0.011    &       -0.011     \\\\\n\\textbf{x14}   &      -0.0002  &     5.65e-05     &    -4.043  &         0.000        &       -0.000    &       -0.000     \\\\\n\\textbf{x15}   &      -0.0133  &     5.93e-05     &  -223.663  &         0.000        &       -0.013    &       -0.013     \\\\\n\\textbf{x16}   &      -0.0002  &     6.31e-05     &    -3.685  &         0.000        &       -0.000    &       -0.000     \\\\\n\\textbf{x17}   &   -2.798e-09  &     8.07e-10     &    -3.468  &         0.001        &    -4.38e-09    &    -1.22e-09     \\\\\n\\textbf{x18}   &      -0.0010  &     2.58e-05     &   -38.558  &         0.000        &       -0.001    &       -0.001     \\\\\n\\textbf{x19}   &      -0.0160  &     6.63e-05     &  -241.622  &         0.000        &       -0.016    &       -0.016     \\\\\n\\textbf{x20}   &      -0.0057  &     6.78e-05     &   -83.469  &         0.000        &       -0.006    &       -0.006     \\\\\n\\textbf{x21}   &       0.0020  &        7e-05     &    29.227  &         0.000        &        0.002    &        0.002     \\\\\n\\textbf{x22}   &      -0.0006  &        0.000     &    -5.612  &         0.000        &       -0.001    &       -0.000     \\\\\n\\textbf{x23}   &       0.0004  &     8.04e-05     &     5.454  &         0.000        &        0.000    &        0.001     \\\\\n\\textbf{x24}   &       0.0005  &     9.58e-05     &     5.523  &         0.000        &        0.000    &        0.001     \\\\\n\\textbf{x25}   &       0.0005  &        0.000     &     4.332  &         0.000        &        0.000    &        0.001     \\\\\n\\textbf{x26}   &       0.0004  &        0.000     &     3.319  &         0.001        &        0.000    &        0.001     \\\\\n\\textbf{x27}   &       0.0015  &        0.000     &    11.004  &         0.000        &        0.001    &        0.002     \\\\\n\\textbf{x28}   &       0.0011  &        0.000     &     6.325  &         0.000        &        0.001    &        0.001     \\\\\n\\textbf{x29}   &     1.52e-05  &     7.31e-07     &    20.794  &         0.000        &     1.38e-05    &     1.66e-05     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 593907.717 & \\textbf{  Durbin-Watson:     } &       1.972     \\\\\n\\textbf{Prob(Omnibus):} &    0.000   & \\textbf{  Jarque-Bera (JB):  } & 5890682278.015  \\\\\n\\textbf{Skew:}          &   17.570   & \\textbf{  Prob(JB):          } &        0.00     \\\\\n\\textbf{Kurtosis:}      &  706.675   & \\textbf{  Cond. No.          } &    1.12e+16     \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The smallest eigenvalue is 5.11e-17. This might indicate that there are \\newline\n strong multicollinearity problems or that the design matrix is singular."
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "#all features are important since p(t)<0.5\n",
        "X_opt = X[:, [0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15,16,1,7,18,19,20,21,23,24,26,27,28,29,30]]\n",
        "X_opt = X_opt.astype(np.float64)\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
        "regressor_OLS.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO0oIz5fnn3n"
      },
      "outputs": [],
      "source": [
        "#splitting the model into training and testing dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(X_opt,y,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "kct1kbUhn0Ue",
        "outputId": "51990b3f-4265-495b-9514-c3215ea8d4d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(n_estimators=10, random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_estimators=10, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=10, random_state=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "#building and training the model\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "regression = GradientBoostingClassifier(n_estimators=10,random_state=1)\n",
        "regression.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_uIueqtoCq0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSCtzc5hn2If"
      },
      "outputs": [],
      "source": [
        "#predicting the values\n",
        "y_pred = regression.predict(x_test)\n",
        "np.set_printoptions(precision=2)\n",
        "#print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL6PdqoYn4Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5375d01-0f77-4da0-90e9-da12bdfc53cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.90695551420245 %\n"
          ]
        }
      ],
      "source": [
        "#calculation of regression score\n",
        "r2_score = regression.score(x_test,y_test)\n",
        "print(r2_score*100,'%')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using cross validation method\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = regression, X = x_train, y = y_train, cv = 2)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lTWWMLoIESF",
        "outputId": "e56f7a81-3e2c-48d5-fecd-bfd87d0548e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 99.86 %\n",
            "Standard Deviation: 0.04 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing confusion matrix and accuracy score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = regression.predict(x_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFGZycTwfVUd",
        "outputId": "f7151118-c805-47ee-b93b-452e933133e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[56845    16]\n",
            " [   37    64]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9990695551420246"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LYfYAcadf-xk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}